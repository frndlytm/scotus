{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d42b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, download, TextCleaner, TextParser, BoWTransformer\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63950af",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(filename=\"/Users/vaughnfranz/.convokit/downloads/supreme-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76787002",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "\n",
    "Below I define a couple of custom cleaning functions to complement the built in cleaning capabilites of convokit.\n",
    "\n",
    "The TextCleaner transformer from convokit operates on a string, so these functions do as well. \n",
    "\n",
    "The first function removes punctuation. The second removes stopwords and lemmatizes the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b569c13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vaughnfranz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vaughnfranz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/vaughnfranz/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordNetLemm = WordNetLemmatizer()\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    cleaned = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return cleaned\n",
    "\n",
    "def custom_cleaner(text):\n",
    "    toks = text.split()\n",
    "    toks = [word for word in toks if not word in stop_words]\n",
    "    toks = [wordNetLemm.lemmatize(word) for word in toks]\n",
    "    cleaned = \" \".join(toks)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdebb4b",
   "metadata": {},
   "source": [
    "I'm going to start wiht removing the punctuation, then use the built in cleaning functionality, and then do the additional cleaning. The reason for this is to avoid affecting the special tokens which convokit inserts for numbers and the like.\n",
    "\n",
    "Verbosity of 250,000 feels reasonable for 1.7+ million utterances, so I will use that number throughout. \n",
    "\n",
    "The TextCleaner class of convokit takes a keyword arg that allows us to specify a custom cleaining function to apply to each utterance. \n",
    "\n",
    "With replace set to False the cleaner should store the cleaned text in an attribute on the utterances called 'cleaned.' The original text will be preserved in 'text.' I will then do the additional cleaning steps on the 'cleaned' attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37699eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000/1700789 utterances processed\n",
      "500000/1700789 utterances processed\n",
      "750000/1700789 utterances processed\n",
      "1000000/1700789 utterances processed\n",
      "1250000/1700789 utterances processed\n",
      "1500000/1700789 utterances processed\n",
      "1700789/1700789 utterances processed\n"
     ]
    }
   ],
   "source": [
    "corpus = TextCleaner(verbosity=250000, text_cleaner=remove_punctuation, replace_text=False).transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128438a",
   "metadata": {},
   "source": [
    "Let's make sure the cleaning is operating more or less as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf909c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL: Number 71, Lonnie Affronti versus United States of America.\n",
      "Mr. Murphy.\n",
      "CLEANED: Number 71 Lonnie Affronti versus United States of America\n",
      "Mr Murphy\n"
     ]
    }
   ],
   "source": [
    "test_utterance_id = '13127__0_000'\n",
    "utt = corpus.get_utterance(test_utterance_id)\n",
    "print('ORIGINAL:', utt.text)\n",
    "print('CLEANED:', utt.meta['cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d67d9",
   "metadata": {},
   "source": [
    "Cleaning using the built in functionality of convokit. \n",
    "\n",
    "The TextCleaner will, by default:\n",
    "- fix unicode errors, transliterate text to the closest ASCII representation\n",
    "- lowercase text\n",
    "- remove line breaks\n",
    "- replace URLs, emails, phone numbers, numbers, and currency symbols with special tokens\n",
    "\n",
    "The cleaner will operate by default on the utterances (specifically, utterance.text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a6b0d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000/1700789 utterances processed\n",
      "500000/1700789 utterances processed\n",
      "750000/1700789 utterances processed\n",
      "1000000/1700789 utterances processed\n",
      "1250000/1700789 utterances processed\n",
      "1500000/1700789 utterances processed\n",
      "1700789/1700789 utterances processed\n"
     ]
    }
   ],
   "source": [
    "corpus = TextCleaner(verbosity=250000, input_field='cleaned', replace_text=False).transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a97004",
   "metadata": {},
   "source": [
    "Another sanity test on the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326e6a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: 13127__0_000\n",
      "ORIGINAL: Number 71, Lonnie Affronti versus United States of America.\n",
      "Mr. Murphy.\n",
      "CLEANED: number <number> lonnie affronti versus united states of america mr murphy\n",
      "TEST: 13127__0_004\n",
      "ORIGINAL: Was the aggregate prison sentence was 20 or 25 years?\n",
      "CLEANED: was the aggregate prison sentence was <number> or <number> years\n"
     ]
    }
   ],
   "source": [
    "test_utterance_id = '13127__0_000'\n",
    "test_utterance_id_2 = '13127__0_004'\n",
    "utt = corpus.get_utterance(test_utterance_id)\n",
    "print('TEST: 13127__0_000')\n",
    "print('ORIGINAL:', utt.text)\n",
    "print('CLEANED:', utt.meta['cleaned'])\n",
    "utt2 = corpus.get_utterance(test_utterance_id_2)\n",
    "print('TEST: 13127__0_004')\n",
    "print('ORIGINAL:', utt2.text)\n",
    "print('CLEANED:', utt2.meta['cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fece6a",
   "metadata": {},
   "source": [
    "Now performing our other custom cleaning steps as defined in the function up top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54b0c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000/1700789 utterances processed\n",
      "500000/1700789 utterances processed\n",
      "750000/1700789 utterances processed\n",
      "1000000/1700789 utterances processed\n",
      "1250000/1700789 utterances processed\n",
      "1500000/1700789 utterances processed\n",
      "1700789/1700789 utterances processed\n"
     ]
    }
   ],
   "source": [
    "corpus = TextCleaner(verbosity=250000, text_cleaner=custom_cleaner, input_field='cleaned', replace_text=False).transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc7a8d",
   "metadata": {},
   "source": [
    "Sanity test again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb9c05da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: 13127__0_000\n",
      "ORIGINAL: Number 71, Lonnie Affronti versus United States of America.\n",
      "Mr. Murphy.\n",
      "CLEANED: number <number> lonnie affronti versus united state america mr murphy\n",
      "TEST: 13127__0_004\n",
      "ORIGINAL: Was the aggregate prison sentence was 20 or 25 years?\n",
      "CLEANED: aggregate prison sentence <number> <number> year\n"
     ]
    }
   ],
   "source": [
    "test_utterance_id = '13127__0_000'\n",
    "test_utterance_id_2 = '13127__0_004'\n",
    "utt = corpus.get_utterance(test_utterance_id)\n",
    "print('TEST: 13127__0_000')\n",
    "print('ORIGINAL:', utt.text)\n",
    "print('CLEANED:', utt.meta['cleaned'])\n",
    "utt2 = corpus.get_utterance(test_utterance_id_2)\n",
    "print('TEST: 13127__0_004')\n",
    "print('ORIGINAL:', utt2.text)\n",
    "print('CLEANED:', utt2.meta['cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6682f",
   "metadata": {},
   "source": [
    "### OMIT THIS -- DOES NOT WORK AS ANTICIPATED \n",
    "\n",
    "Now, we use the TextParser to tokenize our cleaned strings. \n",
    "\n",
    "I'm going to use a custom tokenizer here which simply splits the sentences on spaces. This will give us our desired output as a list of strings which is needed for the gensim Word2Vec model. \n",
    "\n",
    "This uses nltk's sentence tokenizer by default. The output will be stored in a field called 'parsed.'\n",
    "\n",
    "If you want to run this you need to make sure spacy's english model is downloaded. You can do this by running:\n",
    "\n",
    "``` python -m spacy download en ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68275cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    toks = text.split()\n",
    "    return toks \n",
    "# corpus = TextParser(verbosity=250000, sent_tokenizer=custom_tokenizer, input_field='cleaned', mode='tokenize').transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577365ab",
   "metadata": {},
   "source": [
    "## Putting the data together \n",
    "Now we can get our dataframes, and connect the case information with the utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d6a990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df = corpus.get_utterances_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a45cd55",
   "metadata": {},
   "source": [
    "Dropping the parsed column from the misstep in using convokit's TextParser earlier... You don't need to run this if you skipped the earlier step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8d16dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df = utterances_df.drop(columns=['meta.parsed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38033b39",
   "metadata": {},
   "source": [
    "Saving the dataframe to a file for safe keeping so that the above steps do not need to be repeated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7da56aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df.to_csv(path_or_buf=\"parsed_utterances.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad99ba5",
   "metadata": {},
   "source": [
    "Now lets actually tokenize our text, using the custom tokenizer defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35357c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df['tokens'] = utterances_df['meta.cleaned'].apply(custom_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb69d6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.case_id</th>\n",
       "      <th>meta.start_times</th>\n",
       "      <th>meta.stop_times</th>\n",
       "      <th>meta.speaker_type</th>\n",
       "      <th>meta.side</th>\n",
       "      <th>meta.timestamp</th>\n",
       "      <th>meta.cleaned</th>\n",
       "      <th>vectors</th>\n",
       "      <th>tokens</th>\n",
       "      <th>meta.win_side</th>\n",
       "      <th>meta.votes_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Number 71, Lonnie Affronti versus United State...</td>\n",
       "      <td>j__earl_warren</td>\n",
       "      <td>None</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[0.0, 7.624]</td>\n",
       "      <td>[7.624, 9.218]</td>\n",
       "      <td>J</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>number &lt;number&gt; lonnie affronti versus united ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[number, &lt;number&gt;, lonnie, affronti, versus, u...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>May it please the Court.\\nWe are here by writ ...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_000</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[9.218, 11.538, 15.653, 22.722, 28.849, 33.575]</td>\n",
       "      <td>[11.538, 15.653, 22.722, 28.849, 33.575, 48.138]</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>9.218</td>\n",
       "      <td>may please court writ certiorari eighth circui...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[may, please, court, writ, certiorari, eighth,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.</td>\n",
       "      <td>j__william_o_douglas</td>\n",
       "      <td>13127__0_001</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[48.138]</td>\n",
       "      <td>[49.315]</td>\n",
       "      <td>J</td>\n",
       "      <td>None</td>\n",
       "      <td>48.138</td>\n",
       "      <td>consecutive sentence</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.\\nIn this case, the defe...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_002</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[49.315, 51.844, 60.81, 67.083, 72.584, 89.839...</td>\n",
       "      <td>[51.844, 60.81, 67.083, 72.584, 89.839, 95.873...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>49.315</td>\n",
       "      <td>consecutive sentence case defendant affronti i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence, case, defendant, affro...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Was the aggregate prison sentence was 20 or 25...</td>\n",
       "      <td>&lt;INAUDIBLE&gt;</td>\n",
       "      <td>13127__0_003</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[174.058]</td>\n",
       "      <td>[176.766]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>174.058</td>\n",
       "      <td>aggregate prison sentence &lt;number&gt; &lt;number&gt; year</td>\n",
       "      <td>[]</td>\n",
       "      <td>[aggregate, prison, sentence, &lt;number&gt;, &lt;numbe...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp                                               text  \\\n",
       "0      None  Number 71, Lonnie Affronti versus United State...   \n",
       "1      None  May it please the Court.\\nWe are here by writ ...   \n",
       "2      None                             Consecutive sentences.   \n",
       "3      None  Consecutive sentences.\\nIn this case, the defe...   \n",
       "4      None  Was the aggregate prison sentence was 20 or 25...   \n",
       "\n",
       "                speaker      reply_to conversation_id meta.case_id  \\\n",
       "0        j__earl_warren          None           13127      1955_71   \n",
       "1        harry_f_murphy  13127__0_000           13127      1955_71   \n",
       "2  j__william_o_douglas  13127__0_001           13127      1955_71   \n",
       "3        harry_f_murphy  13127__0_002           13127      1955_71   \n",
       "4           <INAUDIBLE>  13127__0_003           13127      1955_71   \n",
       "\n",
       "                                    meta.start_times  \\\n",
       "0                                       [0.0, 7.624]   \n",
       "1    [9.218, 11.538, 15.653, 22.722, 28.849, 33.575]   \n",
       "2                                           [48.138]   \n",
       "3  [49.315, 51.844, 60.81, 67.083, 72.584, 89.839...   \n",
       "4                                          [174.058]   \n",
       "\n",
       "                                     meta.stop_times meta.speaker_type  \\\n",
       "0                                     [7.624, 9.218]                 J   \n",
       "1   [11.538, 15.653, 22.722, 28.849, 33.575, 48.138]                 A   \n",
       "2                                           [49.315]                 J   \n",
       "3  [51.844, 60.81, 67.083, 72.584, 89.839, 95.873...                 A   \n",
       "4                                          [176.766]              None   \n",
       "\n",
       "  meta.side meta.timestamp                                       meta.cleaned  \\\n",
       "0      None            0.0  number <number> lonnie affronti versus united ...   \n",
       "1         1          9.218  may please court writ certiorari eighth circui...   \n",
       "2      None         48.138                               consecutive sentence   \n",
       "3         1         49.315  consecutive sentence case defendant affronti i...   \n",
       "4      None        174.058   aggregate prison sentence <number> <number> year   \n",
       "\n",
       "  vectors                                             tokens meta.win_side  \\\n",
       "0      []  [number, <number>, lonnie, affronti, versus, u...             0   \n",
       "1      []  [may, please, court, writ, certiorari, eighth,...             0   \n",
       "2      []                            [consecutive, sentence]             0   \n",
       "3      []  [consecutive, sentence, case, defendant, affro...             0   \n",
       "4      []  [aggregate, prison, sentence, <number>, <numbe...             0   \n",
       "\n",
       "                                     meta.votes_side  \n",
       "0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  \n",
       "1  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  \n",
       "2  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  \n",
       "3  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  \n",
       "4  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b913b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_df = corpus.get_conversations_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "332b61c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectors</th>\n",
       "      <th>meta.case_id</th>\n",
       "      <th>meta.advocates</th>\n",
       "      <th>meta.win_side</th>\n",
       "      <th>meta.votes_side</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13127</th>\n",
       "      <td>[]</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>{'harry_f_murphy': {'side': 1, 'role': 'inferr...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>[]</td>\n",
       "      <td>1955_410</td>\n",
       "      <td>{'howard_c_westwood': {'side': 1, 'role': 'inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13024</th>\n",
       "      <td>[]</td>\n",
       "      <td>1955_410</td>\n",
       "      <td>{'howard_c_westwood': {'side': 1, 'role': 'inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13015</th>\n",
       "      <td>[]</td>\n",
       "      <td>1955_351</td>\n",
       "      <td>{'harry_d_graham': {'side': 3, 'role': 'inferr...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13016</th>\n",
       "      <td>[]</td>\n",
       "      <td>1955_38</td>\n",
       "      <td>{'robert_n_gorman': {'side': 3, 'role': 'infer...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      vectors meta.case_id                                     meta.advocates  \\\n",
       "id                                                                              \n",
       "13127      []      1955_71  {'harry_f_murphy': {'side': 1, 'role': 'inferr...   \n",
       "12997      []     1955_410  {'howard_c_westwood': {'side': 1, 'role': 'inf...   \n",
       "13024      []     1955_410  {'howard_c_westwood': {'side': 1, 'role': 'inf...   \n",
       "13015      []     1955_351  {'harry_d_graham': {'side': 3, 'role': 'inferr...   \n",
       "13016      []      1955_38  {'robert_n_gorman': {'side': 3, 'role': 'infer...   \n",
       "\n",
       "      meta.win_side                                    meta.votes_side  \n",
       "id                                                                      \n",
       "13127             0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  \n",
       "12997             1  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...  \n",
       "13024             1  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...  \n",
       "13015             1  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...  \n",
       "13016             0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e9efc",
   "metadata": {},
   "source": [
    "We can use the pandas built in merge function to bring in the case information to the utterances df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5398717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df = pd.merge(utterances_df, conversations_df[['meta.case_id', 'meta.win_side', 'meta.votes_side']], how='left', left_on='meta.case_id', right_on='meta.case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6434e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.case_id</th>\n",
       "      <th>meta.start_times</th>\n",
       "      <th>meta.stop_times</th>\n",
       "      <th>meta.speaker_type</th>\n",
       "      <th>meta.side</th>\n",
       "      <th>meta.timestamp</th>\n",
       "      <th>meta.cleaned</th>\n",
       "      <th>vectors</th>\n",
       "      <th>tokens</th>\n",
       "      <th>meta.win_side</th>\n",
       "      <th>meta.votes_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Number 71, Lonnie Affronti versus United State...</td>\n",
       "      <td>j__earl_warren</td>\n",
       "      <td>None</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[0.0, 7.624]</td>\n",
       "      <td>[7.624, 9.218]</td>\n",
       "      <td>J</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>number &lt;number&gt; lonnie affronti versus united ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[number, &lt;number&gt;, lonnie, affronti, versus, u...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>May it please the Court.\\nWe are here by writ ...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_000</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[9.218, 11.538, 15.653, 22.722, 28.849, 33.575]</td>\n",
       "      <td>[11.538, 15.653, 22.722, 28.849, 33.575, 48.138]</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>9.218</td>\n",
       "      <td>may please court writ certiorari eighth circui...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[may, please, court, writ, certiorari, eighth,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.</td>\n",
       "      <td>j__william_o_douglas</td>\n",
       "      <td>13127__0_001</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[48.138]</td>\n",
       "      <td>[49.315]</td>\n",
       "      <td>J</td>\n",
       "      <td>None</td>\n",
       "      <td>48.138</td>\n",
       "      <td>consecutive sentence</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.\\nIn this case, the defe...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_002</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[49.315, 51.844, 60.81, 67.083, 72.584, 89.839...</td>\n",
       "      <td>[51.844, 60.81, 67.083, 72.584, 89.839, 95.873...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>49.315</td>\n",
       "      <td>consecutive sentence case defendant affronti i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence, case, defendant, affro...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Was the aggregate prison sentence was 20 or 25...</td>\n",
       "      <td>&lt;INAUDIBLE&gt;</td>\n",
       "      <td>13127__0_003</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[174.058]</td>\n",
       "      <td>[176.766]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>174.058</td>\n",
       "      <td>aggregate prison sentence &lt;number&gt; &lt;number&gt; year</td>\n",
       "      <td>[]</td>\n",
       "      <td>[aggregate, prison, sentence, &lt;number&gt;, &lt;numbe...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp                                               text  \\\n",
       "0      None  Number 71, Lonnie Affronti versus United State...   \n",
       "1      None  May it please the Court.\\nWe are here by writ ...   \n",
       "2      None                             Consecutive sentences.   \n",
       "3      None  Consecutive sentences.\\nIn this case, the defe...   \n",
       "4      None  Was the aggregate prison sentence was 20 or 25...   \n",
       "\n",
       "                speaker      reply_to conversation_id meta.case_id  \\\n",
       "0        j__earl_warren          None           13127      1955_71   \n",
       "1        harry_f_murphy  13127__0_000           13127      1955_71   \n",
       "2  j__william_o_douglas  13127__0_001           13127      1955_71   \n",
       "3        harry_f_murphy  13127__0_002           13127      1955_71   \n",
       "4           <INAUDIBLE>  13127__0_003           13127      1955_71   \n",
       "\n",
       "                                    meta.start_times  \\\n",
       "0                                       [0.0, 7.624]   \n",
       "1    [9.218, 11.538, 15.653, 22.722, 28.849, 33.575]   \n",
       "2                                           [48.138]   \n",
       "3  [49.315, 51.844, 60.81, 67.083, 72.584, 89.839...   \n",
       "4                                          [174.058]   \n",
       "\n",
       "                                     meta.stop_times meta.speaker_type  \\\n",
       "0                                     [7.624, 9.218]                 J   \n",
       "1   [11.538, 15.653, 22.722, 28.849, 33.575, 48.138]                 A   \n",
       "2                                           [49.315]                 J   \n",
       "3  [51.844, 60.81, 67.083, 72.584, 89.839, 95.873...                 A   \n",
       "4                                          [176.766]              None   \n",
       "\n",
       "  meta.side meta.timestamp                                       meta.cleaned  \\\n",
       "0      None            0.0  number <number> lonnie affronti versus united ...   \n",
       "1         1          9.218  may please court writ certiorari eighth circui...   \n",
       "2      None         48.138                               consecutive sentence   \n",
       "3         1         49.315  consecutive sentence case defendant affronti i...   \n",
       "4      None        174.058   aggregate prison sentence <number> <number> year   \n",
       "\n",
       "  vectors                                             tokens meta.win_side  \\\n",
       "0      []  [number, <number>, lonnie, affronti, versus, u...             0   \n",
       "1      []  [may, please, court, writ, certiorari, eighth,...             0   \n",
       "2      []                            [consecutive, sentence]             0   \n",
       "3      []  [consecutive, sentence, case, defendant, affro...             0   \n",
       "4      []  [aggregate, prison, sentence, <number>, <numbe...             0   \n",
       "\n",
       "                                     meta.votes_side  \n",
       "0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  \n",
       "1  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  \n",
       "2  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  \n",
       "3  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  \n",
       "4  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "430f4adf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1378597\n",
       " 0     796114\n",
       " 2        831\n",
       "-1        374\n",
       "Name: meta.win_side, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df['meta.win_side'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f907e",
   "metadata": {},
   "source": [
    "According to convokit documentation a 2 signifies that the decision was unclear and a -1 signifies that the data was unavailable. We can drop these rows to simplify the classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81b8093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df = utterances_df[utterances_df['meta.win_side'] != 2]\n",
    "utterances_df = utterances_df[utterances_df['meta.win_side'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "983f032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1378597\n",
       "0     796114\n",
       "Name: meta.win_side, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df['meta.win_side'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542f3508",
   "metadata": {},
   "source": [
    "We are also going to make use of the speaker information in our models, so let's examine that and drop data where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8d4fa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    1056973\n",
       "J    1012327\n",
       "Name: meta.speaker_type, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df['meta.speaker_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb44be",
   "metadata": {},
   "source": [
    "We also need to do a one-hot-encoding of the speakers for our model. Doing that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af9576b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df = pd.get_dummies(utterances_df, prefix=['speaker_type'], columns=['meta.speaker_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16d70636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.case_id</th>\n",
       "      <th>meta.start_times</th>\n",
       "      <th>meta.stop_times</th>\n",
       "      <th>meta.side</th>\n",
       "      <th>meta.timestamp</th>\n",
       "      <th>meta.cleaned</th>\n",
       "      <th>vectors</th>\n",
       "      <th>tokens</th>\n",
       "      <th>meta.win_side</th>\n",
       "      <th>meta.votes_side</th>\n",
       "      <th>speaker_type_A</th>\n",
       "      <th>speaker_type_J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Number 71, Lonnie Affronti versus United State...</td>\n",
       "      <td>j__earl_warren</td>\n",
       "      <td>None</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[0.0, 7.624]</td>\n",
       "      <td>[7.624, 9.218]</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>number &lt;number&gt; lonnie affronti versus united ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[number, &lt;number&gt;, lonnie, affronti, versus, u...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>May it please the Court.\\nWe are here by writ ...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_000</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[9.218, 11.538, 15.653, 22.722, 28.849, 33.575]</td>\n",
       "      <td>[11.538, 15.653, 22.722, 28.849, 33.575, 48.138]</td>\n",
       "      <td>1</td>\n",
       "      <td>9.218</td>\n",
       "      <td>may please court writ certiorari eighth circui...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[may, please, court, writ, certiorari, eighth,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.</td>\n",
       "      <td>j__william_o_douglas</td>\n",
       "      <td>13127__0_001</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[48.138]</td>\n",
       "      <td>[49.315]</td>\n",
       "      <td>None</td>\n",
       "      <td>48.138</td>\n",
       "      <td>consecutive sentence</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.\\nIn this case, the defe...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_002</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[49.315, 51.844, 60.81, 67.083, 72.584, 89.839...</td>\n",
       "      <td>[51.844, 60.81, 67.083, 72.584, 89.839, 95.873...</td>\n",
       "      <td>1</td>\n",
       "      <td>49.315</td>\n",
       "      <td>consecutive sentence case defendant affronti i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence, case, defendant, affro...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Was the aggregate prison sentence was 20 or 25...</td>\n",
       "      <td>&lt;INAUDIBLE&gt;</td>\n",
       "      <td>13127__0_003</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[174.058]</td>\n",
       "      <td>[176.766]</td>\n",
       "      <td>None</td>\n",
       "      <td>174.058</td>\n",
       "      <td>aggregate prison sentence &lt;number&gt; &lt;number&gt; year</td>\n",
       "      <td>[]</td>\n",
       "      <td>[aggregate, prison, sentence, &lt;number&gt;, &lt;numbe...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp                                               text  \\\n",
       "0      None  Number 71, Lonnie Affronti versus United State...   \n",
       "1      None  May it please the Court.\\nWe are here by writ ...   \n",
       "2      None                             Consecutive sentences.   \n",
       "3      None  Consecutive sentences.\\nIn this case, the defe...   \n",
       "4      None  Was the aggregate prison sentence was 20 or 25...   \n",
       "\n",
       "                speaker      reply_to conversation_id meta.case_id  \\\n",
       "0        j__earl_warren          None           13127      1955_71   \n",
       "1        harry_f_murphy  13127__0_000           13127      1955_71   \n",
       "2  j__william_o_douglas  13127__0_001           13127      1955_71   \n",
       "3        harry_f_murphy  13127__0_002           13127      1955_71   \n",
       "4           <INAUDIBLE>  13127__0_003           13127      1955_71   \n",
       "\n",
       "                                    meta.start_times  \\\n",
       "0                                       [0.0, 7.624]   \n",
       "1    [9.218, 11.538, 15.653, 22.722, 28.849, 33.575]   \n",
       "2                                           [48.138]   \n",
       "3  [49.315, 51.844, 60.81, 67.083, 72.584, 89.839...   \n",
       "4                                          [174.058]   \n",
       "\n",
       "                                     meta.stop_times meta.side meta.timestamp  \\\n",
       "0                                     [7.624, 9.218]      None            0.0   \n",
       "1   [11.538, 15.653, 22.722, 28.849, 33.575, 48.138]         1          9.218   \n",
       "2                                           [49.315]      None         48.138   \n",
       "3  [51.844, 60.81, 67.083, 72.584, 89.839, 95.873...         1         49.315   \n",
       "4                                          [176.766]      None        174.058   \n",
       "\n",
       "                                        meta.cleaned vectors  \\\n",
       "0  number <number> lonnie affronti versus united ...      []   \n",
       "1  may please court writ certiorari eighth circui...      []   \n",
       "2                               consecutive sentence      []   \n",
       "3  consecutive sentence case defendant affronti i...      []   \n",
       "4   aggregate prison sentence <number> <number> year      []   \n",
       "\n",
       "                                              tokens meta.win_side  \\\n",
       "0  [number, <number>, lonnie, affronti, versus, u...             0   \n",
       "1  [may, please, court, writ, certiorari, eighth,...             0   \n",
       "2                            [consecutive, sentence]             0   \n",
       "3  [consecutive, sentence, case, defendant, affro...             0   \n",
       "4  [aggregate, prison, sentence, <number>, <numbe...             0   \n",
       "\n",
       "                                     meta.votes_side  speaker_type_A  \\\n",
       "0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               0   \n",
       "1  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               1   \n",
       "2  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               0   \n",
       "3  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               1   \n",
       "4  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               0   \n",
       "\n",
       "   speaker_type_J  \n",
       "0               1  \n",
       "1               0  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc596b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961_8          12672\n",
       "1961_2           7476\n",
       "1965_759         6595\n",
       "1960_6           5576\n",
       "1962_8           4972\n",
       "                ...  \n",
       "1977_76-5935       27\n",
       "1968_574           26\n",
       "1960_340           24\n",
       "2000_99-1884        2\n",
       "2011_10-1195        1\n",
       "Name: meta.case_id, Length: 6728, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df['meta.case_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aec543e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1121336"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df['meta.side'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc14cb",
   "metadata": {},
   "source": [
    "1 - petitioning party\n",
    "\n",
    "0 - respondent\n",
    "\n",
    "2 - amicus curiae\n",
    "\n",
    "3 - unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8d1ed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    416007\n",
       "0    352773\n",
       "3    260734\n",
       "2     27459\n",
       "Name: meta.side, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df['meta.side'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8bb93288",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df['meta.side'].fillna(3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c9650a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1382070\n",
       "1     416007\n",
       "0     352773\n",
       "2      27459\n",
       "Name: meta.side, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df['meta.side'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e1707",
   "metadata": {},
   "source": [
    "## Obtaining embedded utterances \n",
    "\n",
    "We are now going to use gensim in order to obtain embedded utterances. We will use a word2vec model and then will pool the vectors for each utterance. \n",
    "\n",
    "To start, I am going to slice the dataframe down to a specific case and train on that. We will then use that to debug our model pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b07564fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_1955_71 = utterances_df[utterances_df['meta.case_id'] == '1955_71']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29fd988e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 17)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_1955_71.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9f2df95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.case_id</th>\n",
       "      <th>meta.start_times</th>\n",
       "      <th>meta.stop_times</th>\n",
       "      <th>meta.side</th>\n",
       "      <th>meta.timestamp</th>\n",
       "      <th>meta.cleaned</th>\n",
       "      <th>vectors</th>\n",
       "      <th>tokens</th>\n",
       "      <th>meta.win_side</th>\n",
       "      <th>meta.votes_side</th>\n",
       "      <th>speaker_type_A</th>\n",
       "      <th>speaker_type_J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Number 71, Lonnie Affronti versus United State...</td>\n",
       "      <td>j__earl_warren</td>\n",
       "      <td>None</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[0.0, 7.624]</td>\n",
       "      <td>[7.624, 9.218]</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>number &lt;number&gt; lonnie affronti versus united ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[number, &lt;number&gt;, lonnie, affronti, versus, u...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>May it please the Court.\\nWe are here by writ ...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_000</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[9.218, 11.538, 15.653, 22.722, 28.849, 33.575]</td>\n",
       "      <td>[11.538, 15.653, 22.722, 28.849, 33.575, 48.138]</td>\n",
       "      <td>1</td>\n",
       "      <td>9.218</td>\n",
       "      <td>may please court writ certiorari eighth circui...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[may, please, court, writ, certiorari, eighth,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.</td>\n",
       "      <td>j__william_o_douglas</td>\n",
       "      <td>13127__0_001</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[48.138]</td>\n",
       "      <td>[49.315]</td>\n",
       "      <td>None</td>\n",
       "      <td>48.138</td>\n",
       "      <td>consecutive sentence</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.\\nIn this case, the defe...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_002</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[49.315, 51.844, 60.81, 67.083, 72.584, 89.839...</td>\n",
       "      <td>[51.844, 60.81, 67.083, 72.584, 89.839, 95.873...</td>\n",
       "      <td>1</td>\n",
       "      <td>49.315</td>\n",
       "      <td>consecutive sentence case defendant affronti i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence, case, defendant, affro...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Was the aggregate prison sentence was 20 or 25...</td>\n",
       "      <td>&lt;INAUDIBLE&gt;</td>\n",
       "      <td>13127__0_003</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[174.058]</td>\n",
       "      <td>[176.766]</td>\n",
       "      <td>None</td>\n",
       "      <td>174.058</td>\n",
       "      <td>aggregate prison sentence &lt;number&gt; &lt;number&gt; year</td>\n",
       "      <td>[]</td>\n",
       "      <td>[aggregate, prison, sentence, &lt;number&gt;, &lt;numbe...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp                                               text  \\\n",
       "0      None  Number 71, Lonnie Affronti versus United State...   \n",
       "1      None  May it please the Court.\\nWe are here by writ ...   \n",
       "2      None                             Consecutive sentences.   \n",
       "3      None  Consecutive sentences.\\nIn this case, the defe...   \n",
       "4      None  Was the aggregate prison sentence was 20 or 25...   \n",
       "\n",
       "                speaker      reply_to conversation_id meta.case_id  \\\n",
       "0        j__earl_warren          None           13127      1955_71   \n",
       "1        harry_f_murphy  13127__0_000           13127      1955_71   \n",
       "2  j__william_o_douglas  13127__0_001           13127      1955_71   \n",
       "3        harry_f_murphy  13127__0_002           13127      1955_71   \n",
       "4           <INAUDIBLE>  13127__0_003           13127      1955_71   \n",
       "\n",
       "                                    meta.start_times  \\\n",
       "0                                       [0.0, 7.624]   \n",
       "1    [9.218, 11.538, 15.653, 22.722, 28.849, 33.575]   \n",
       "2                                           [48.138]   \n",
       "3  [49.315, 51.844, 60.81, 67.083, 72.584, 89.839...   \n",
       "4                                          [174.058]   \n",
       "\n",
       "                                     meta.stop_times meta.side meta.timestamp  \\\n",
       "0                                     [7.624, 9.218]      None            0.0   \n",
       "1   [11.538, 15.653, 22.722, 28.849, 33.575, 48.138]         1          9.218   \n",
       "2                                           [49.315]      None         48.138   \n",
       "3  [51.844, 60.81, 67.083, 72.584, 89.839, 95.873...         1         49.315   \n",
       "4                                          [176.766]      None        174.058   \n",
       "\n",
       "                                        meta.cleaned vectors  \\\n",
       "0  number <number> lonnie affronti versus united ...      []   \n",
       "1  may please court writ certiorari eighth circui...      []   \n",
       "2                               consecutive sentence      []   \n",
       "3  consecutive sentence case defendant affronti i...      []   \n",
       "4   aggregate prison sentence <number> <number> year      []   \n",
       "\n",
       "                                              tokens meta.win_side  \\\n",
       "0  [number, <number>, lonnie, affronti, versus, u...             0   \n",
       "1  [may, please, court, writ, certiorari, eighth,...             0   \n",
       "2                            [consecutive, sentence]             0   \n",
       "3  [consecutive, sentence, case, defendant, affro...             0   \n",
       "4  [aggregate, prison, sentence, <number>, <numbe...             0   \n",
       "\n",
       "                                     meta.votes_side  speaker_type_A  \\\n",
       "0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               0   \n",
       "1  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               1   \n",
       "2  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               0   \n",
       "3  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               1   \n",
       "4  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               0   \n",
       "\n",
       "   speaker_type_J  \n",
       "0               1  \n",
       "1               0  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_1955_71.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3b84f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4825a4a3",
   "metadata": {},
   "source": [
    "Separating the word2vec training into separate steps. We will use a maximum vocabulary size of 10k for our initial training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e0a41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel_1case = Word2Vec(max_vocab_size=10000, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59e93953",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel_1case.build_vocab(case_1955_71['tokens'], progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ea312f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_1955_71['tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdb1ee1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26141, 88380)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_1case.train(case_1955_71['tokens'], total_examples=145, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a311beb",
   "metadata": {},
   "source": [
    "Repeating the same procedure to train the word 2 vec model for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "795b13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel = Word2Vec(max_vocab_size=10000, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c6ed1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel.build_vocab(utterances_df['tokens'], progress_per=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "905a8a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2178309, 17)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b47089bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084870486, 1279023060)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.train(utterances_df['tokens'], total_examples=2178309, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd5885",
   "metadata": {},
   "source": [
    "## Using the Trained W2V model to create embeddings\n",
    "\n",
    "We will combine the vectors for each word in an utterance by averaging them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "22c9f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your word to vec model here as a global variable to be used in the below function\n",
    "w2v = w2vmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "470e4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_pooled_embedding(tokens):\n",
    "    word_embeddings = [w2v.wv[tok] for tok in tokens if tok in w2v.wv]\n",
    "    if len(word_embeddings) > 0:\n",
    "        average = np.mean(word_embeddings, axis=0)\n",
    "    else:\n",
    "        average = np.zeros((300, ))\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6bc36d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df['utterance_embedding'] = utterances_df['tokens'].apply(get_pooled_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "068b0552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/_2dxvpjx083453g4qq1yr83w0000gn/T/ipykernel_62824/961153977.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  case_1955_71['sentence_embedding'] = case_1955_71['tokens'].apply(get_pooled_embedding)\n"
     ]
    }
   ],
   "source": [
    "case_1955_71['utterance_embedding'] = case_1955_71['tokens'].apply(get_pooled_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2761fd52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.case_id</th>\n",
       "      <th>meta.start_times</th>\n",
       "      <th>meta.stop_times</th>\n",
       "      <th>meta.side</th>\n",
       "      <th>meta.timestamp</th>\n",
       "      <th>meta.cleaned</th>\n",
       "      <th>vectors</th>\n",
       "      <th>tokens</th>\n",
       "      <th>meta.win_side</th>\n",
       "      <th>meta.votes_side</th>\n",
       "      <th>speaker_type_A</th>\n",
       "      <th>speaker_type_J</th>\n",
       "      <th>utterance_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Number 71, Lonnie Affronti versus United State...</td>\n",
       "      <td>j__earl_warren</td>\n",
       "      <td>None</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[0.0, 7.624]</td>\n",
       "      <td>[7.624, 9.218]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>number &lt;number&gt; lonnie affronti versus united ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[number, &lt;number&gt;, lonnie, affronti, versus, u...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.8707382, -1.7160745, -0.6207574, 0.2674471...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>May it please the Court.\\nWe are here by writ ...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_000</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[9.218, 11.538, 15.653, 22.722, 28.849, 33.575]</td>\n",
       "      <td>[11.538, 15.653, 22.722, 28.849, 33.575, 48.138]</td>\n",
       "      <td>1</td>\n",
       "      <td>9.218</td>\n",
       "      <td>may please court writ certiorari eighth circui...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[may, please, court, writ, certiorari, eighth,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.51015204, -1.1017727, 0.3864366, -0.0528415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.</td>\n",
       "      <td>j__william_o_douglas</td>\n",
       "      <td>13127__0_001</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[48.138]</td>\n",
       "      <td>[49.315]</td>\n",
       "      <td>3</td>\n",
       "      <td>48.138</td>\n",
       "      <td>consecutive sentence</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.5715005, -0.8253331, 2.721192, -0.25741312,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Consecutive sentences.\\nIn this case, the defe...</td>\n",
       "      <td>harry_f_murphy</td>\n",
       "      <td>13127__0_002</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[49.315, 51.844, 60.81, 67.083, 72.584, 89.839...</td>\n",
       "      <td>[51.844, 60.81, 67.083, 72.584, 89.839, 95.873...</td>\n",
       "      <td>1</td>\n",
       "      <td>49.315</td>\n",
       "      <td>consecutive sentence case defendant affronti i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[consecutive, sentence, case, defendant, affro...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0593424, -0.68631756, 0.1415781, -0.1229764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Was the aggregate prison sentence was 20 or 25...</td>\n",
       "      <td>&lt;INAUDIBLE&gt;</td>\n",
       "      <td>13127__0_003</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>[174.058]</td>\n",
       "      <td>[176.766]</td>\n",
       "      <td>3</td>\n",
       "      <td>174.058</td>\n",
       "      <td>aggregate prison sentence &lt;number&gt; &lt;number&gt; year</td>\n",
       "      <td>[]</td>\n",
       "      <td>[aggregate, prison, sentence, &lt;number&gt;, &lt;numbe...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.26007193, -0.03844468, 0.79606074, -0.3663...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp                                               text  \\\n",
       "0      None  Number 71, Lonnie Affronti versus United State...   \n",
       "1      None  May it please the Court.\\nWe are here by writ ...   \n",
       "2      None                             Consecutive sentences.   \n",
       "3      None  Consecutive sentences.\\nIn this case, the defe...   \n",
       "4      None  Was the aggregate prison sentence was 20 or 25...   \n",
       "\n",
       "                speaker      reply_to conversation_id meta.case_id  \\\n",
       "0        j__earl_warren          None           13127      1955_71   \n",
       "1        harry_f_murphy  13127__0_000           13127      1955_71   \n",
       "2  j__william_o_douglas  13127__0_001           13127      1955_71   \n",
       "3        harry_f_murphy  13127__0_002           13127      1955_71   \n",
       "4           <INAUDIBLE>  13127__0_003           13127      1955_71   \n",
       "\n",
       "                                    meta.start_times  \\\n",
       "0                                       [0.0, 7.624]   \n",
       "1    [9.218, 11.538, 15.653, 22.722, 28.849, 33.575]   \n",
       "2                                           [48.138]   \n",
       "3  [49.315, 51.844, 60.81, 67.083, 72.584, 89.839...   \n",
       "4                                          [174.058]   \n",
       "\n",
       "                                     meta.stop_times  meta.side  \\\n",
       "0                                     [7.624, 9.218]          3   \n",
       "1   [11.538, 15.653, 22.722, 28.849, 33.575, 48.138]          1   \n",
       "2                                           [49.315]          3   \n",
       "3  [51.844, 60.81, 67.083, 72.584, 89.839, 95.873...          1   \n",
       "4                                          [176.766]          3   \n",
       "\n",
       "  meta.timestamp                                       meta.cleaned vectors  \\\n",
       "0            0.0  number <number> lonnie affronti versus united ...      []   \n",
       "1          9.218  may please court writ certiorari eighth circui...      []   \n",
       "2         48.138                               consecutive sentence      []   \n",
       "3         49.315  consecutive sentence case defendant affronti i...      []   \n",
       "4        174.058   aggregate prison sentence <number> <number> year      []   \n",
       "\n",
       "                                              tokens meta.win_side  \\\n",
       "0  [number, <number>, lonnie, affronti, versus, u...             0   \n",
       "1  [may, please, court, writ, certiorari, eighth,...             0   \n",
       "2                            [consecutive, sentence]             0   \n",
       "3  [consecutive, sentence, case, defendant, affro...             0   \n",
       "4  [aggregate, prison, sentence, <number>, <numbe...             0   \n",
       "\n",
       "                                     meta.votes_side  speaker_type_A  \\\n",
       "0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               0   \n",
       "1  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               1   \n",
       "2  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               0   \n",
       "3  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               1   \n",
       "4  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...               0   \n",
       "\n",
       "   speaker_type_J                                utterance_embedding  \n",
       "0               1  [-0.8707382, -1.7160745, -0.6207574, 0.2674471...  \n",
       "1               0  [0.51015204, -1.1017727, 0.3864366, -0.0528415...  \n",
       "2               1  [1.5715005, -0.8253331, 2.721192, -0.25741312,...  \n",
       "3               0  [0.0593424, -0.68631756, 0.1415781, -0.1229764...  \n",
       "4               0  [-0.26007193, -0.03844468, 0.79606074, -0.3663...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "67ba30a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df['utterance_embedding'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ff0986cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df = utterances_df[[\"utterance_embedding\", \"speaker_type_A\", \"speaker_type_J\", \"meta.side\", \"meta.win_side\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "90488d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_embedding</th>\n",
       "      <th>speaker_type_A</th>\n",
       "      <th>speaker_type_J</th>\n",
       "      <th>meta.side</th>\n",
       "      <th>meta.win_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.8707382, -1.7160745, -0.6207574, 0.2674471...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.51015204, -1.1017727, 0.3864366, -0.0528415...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.5715005, -0.8253331, 2.721192, -0.25741312,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0593424, -0.68631756, 0.1415781, -0.1229764...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.26007193, -0.03844468, 0.79606074, -0.3663...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 utterance_embedding  speaker_type_A  \\\n",
       "0  [-0.8707382, -1.7160745, -0.6207574, 0.2674471...               0   \n",
       "1  [0.51015204, -1.1017727, 0.3864366, -0.0528415...               1   \n",
       "2  [1.5715005, -0.8253331, 2.721192, -0.25741312,...               0   \n",
       "3  [0.0593424, -0.68631756, 0.1415781, -0.1229764...               1   \n",
       "4  [-0.26007193, -0.03844468, 0.79606074, -0.3663...               0   \n",
       "\n",
       "   speaker_type_J  meta.side meta.win_side  \n",
       "0               1          3             0  \n",
       "1               0          1             0  \n",
       "2               1          3             0  \n",
       "3               0          1             0  \n",
       "4               0          3             0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9cea2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_np_arr = utterances_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b6b80e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"utterances.npy\", \"wb\") as f:\n",
    "    np.save(f, utt_np_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c64a1c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-8.70738208e-01, -1.71607447e+00, -6.20757401e-01,  2.67447144e-01,\n",
      "        -6.14075065e-02,  2.19559252e-01,  6.26445770e-01,  8.25892448e-01,\n",
      "        -1.00384259e+00, -8.37345868e-02,  6.46695733e-01, -8.64544213e-01,\n",
      "        -1.55116117e+00,  3.29568684e-01,  2.46760815e-01,  5.19752979e-01,\n",
      "        -7.01112270e-01, -3.81856620e-01,  2.01811880e-01, -1.02813005e+00,\n",
      "        -2.31853165e-02,  6.62830174e-01,  5.53926229e-01,  3.87815535e-02,\n",
      "        -8.06790173e-01,  7.83012807e-01,  1.08295488e+00,  1.81906447e-01,\n",
      "         1.32237315e+00,  2.98814178e-01, -3.00511897e-01, -6.92219734e-01,\n",
      "         4.63237166e-01,  6.46214902e-01,  8.44015658e-01, -5.81416965e-01,\n",
      "         1.56645846e+00,  5.40152669e-01, -4.65097725e-01,  7.96111345e-01,\n",
      "        -7.22169876e-01, -7.86633432e-01, -7.08492279e-01, -1.52152598e-01,\n",
      "        -8.63285124e-01,  9.08269942e-01,  6.47146761e-01,  6.08293861e-02,\n",
      "        -3.55272889e-02, -1.20303655e+00,  2.68018395e-01, -1.22896940e-01,\n",
      "         5.09327091e-02,  1.05928576e+00,  8.67322445e-01, -7.24627793e-01,\n",
      "        -2.59865582e-01, -1.08400035e+00, -6.90237820e-01, -3.82624984e-01,\n",
      "        -8.64492416e-01, -8.24174702e-01,  3.38911295e-01,  4.55844164e-01,\n",
      "        -1.62734962e+00, -1.92466930e-01, -2.79477209e-01,  7.81651586e-02,\n",
      "        -4.68936443e-01, -3.10130477e-01,  7.20845699e-01, -1.32798880e-01,\n",
      "         5.00550508e-01, -4.90177333e-01, -2.76187599e-01,  3.89020264e-01,\n",
      "         1.21196181e-01,  2.29411364e-01, -6.00702822e-01,  6.81680501e-01,\n",
      "        -2.51750231e-01, -1.71580672e-01, -2.88198888e-01,  2.22910479e-01,\n",
      "        -9.67697620e-01, -1.03699934e+00,  1.73059666e+00,  3.80616635e-01,\n",
      "         2.68508732e-01,  1.23657691e+00,  5.62501997e-02,  1.09217179e+00,\n",
      "        -6.47407055e-01,  5.83214581e-01, -4.28729534e-01,  9.27163661e-02,\n",
      "        -4.67371225e-01,  2.25721598e-01,  1.67457670e-01, -8.45883965e-01,\n",
      "        -1.19606388e+00,  3.36924314e-01, -5.24241209e-01,  1.45377481e+00,\n",
      "        -1.16361544e-01, -2.30489194e-01,  1.47857055e-01, -1.19754875e+00,\n",
      "         9.73502919e-03,  1.91492274e-01,  2.16156393e-01,  1.02035260e+00,\n",
      "         4.95609045e-01, -2.80153185e-01,  1.15587628e+00,  2.25161180e-01,\n",
      "         1.43960369e+00, -6.91547096e-02,  7.96761870e-01,  3.35312486e-02,\n",
      "        -2.00234652e+00,  8.68414044e-01, -7.66634345e-01, -1.13256371e+00,\n",
      "        -1.93201095e-01, -2.60229260e-01, -3.71761084e-01, -3.50159347e-01,\n",
      "        -1.19979300e-01,  8.82174313e-01,  8.38513196e-01, -1.35831213e+00,\n",
      "         9.20135558e-01,  4.83966231e-01, -7.40535498e-01, -8.68538618e-01,\n",
      "         1.07852370e-02,  6.25938714e-01, -1.32210243e+00, -1.05284286e+00,\n",
      "        -1.99826285e-01,  9.35776949e-01, -6.96779966e-01,  6.59833789e-01,\n",
      "        -2.62135953e-01,  1.03516228e-01,  1.99972808e-01,  7.18530193e-02,\n",
      "         3.22858155e-01, -1.13021600e+00, -2.27455840e-01,  6.55157566e-01,\n",
      "        -4.01169062e-04, -1.98211759e-01, -1.58788788e+00,  4.27446246e-01,\n",
      "        -2.53305912e-01,  2.08012104e-01,  8.80753398e-01, -4.64030206e-02,\n",
      "         3.30305934e-01,  7.73472548e-01, -6.04010165e-01,  1.62839985e+00,\n",
      "         2.65874177e-01,  8.95543545e-02,  6.11246526e-01, -3.25740874e-02,\n",
      "        -9.37783718e-01, -2.74828821e-01, -2.52280653e-01, -3.25414166e-02,\n",
      "         1.03759301e+00,  9.00233015e-02, -1.17653561e+00, -6.93209767e-01,\n",
      "         7.13857710e-02,  4.63450879e-01, -3.50503594e-01,  1.97701752e-01,\n",
      "        -1.21906638e+00, -5.09826779e-01, -4.97632533e-01,  7.75716901e-01,\n",
      "         3.10672998e-01, -2.20416129e-01, -5.45760274e-01, -6.54392898e-01,\n",
      "        -8.21291268e-01,  1.16543806e+00, -1.27122188e+00,  1.05221048e-01,\n",
      "         1.21589279e+00,  2.23581761e-01, -3.39421690e-01, -2.46461779e-01,\n",
      "         1.02643156e+00,  7.23544359e-01, -1.09900916e+00,  6.15575731e-01,\n",
      "         9.81066763e-01, -7.70589471e-01, -3.13008338e-01, -9.85348970e-02,\n",
      "         3.75651002e-01,  1.81772664e-01, -8.28589201e-01,  9.33850467e-01,\n",
      "        -5.28581917e-01, -7.90512502e-01,  1.47531569e-01,  1.21819034e-01,\n",
      "         6.05974972e-01,  9.09398258e-01, -8.97606373e-01,  1.20826638e+00,\n",
      "         2.71836996e-01, -6.22916482e-02,  8.46875906e-01,  5.53453088e-01,\n",
      "        -5.15700519e-01,  1.28404403e+00, -4.15362179e-01,  7.75155842e-01,\n",
      "        -1.28421128e+00,  1.40340924e-02,  7.19341516e-01, -9.38679755e-01,\n",
      "        -8.07102025e-01, -9.49594259e-01, -1.55363217e-01, -8.59041035e-01,\n",
      "         1.02642226e+00,  8.37751552e-02,  7.54180014e-01, -7.10849613e-02,\n",
      "        -2.97848761e-01, -4.04517502e-01,  4.83592659e-01, -1.07752085e-01,\n",
      "        -6.04535580e-01, -1.31451631e+00, -5.92961729e-01, -1.12752986e+00,\n",
      "         2.81912237e-01, -5.35493970e-01,  1.48990750e+00, -6.06786013e-01,\n",
      "        -5.24237752e-01,  3.81123245e-01, -2.08467290e-01, -1.21346605e+00,\n",
      "         1.36472255e-01,  7.53786862e-01,  6.00781143e-01, -6.41058683e-01,\n",
      "         1.34291515e-01,  1.88570291e-01,  6.26180619e-02, -4.06879067e-01,\n",
      "        -1.65677333e+00,  5.56104600e-01,  3.59434485e-02,  7.11774349e-01,\n",
      "         1.96945000e+00,  1.10945880e+00, -6.85498536e-01, -9.40700471e-01,\n",
      "         4.81746256e-01, -8.78991961e-01, -4.61275458e-01,  6.53851867e-01,\n",
      "         1.18083954e+00, -1.72417775e-01, -3.24224234e-01,  1.82227746e-01,\n",
      "        -2.21259594e-01,  2.13132352e-02, -1.13142753e+00, -4.16343093e-01,\n",
      "        -6.45646214e-01, -1.29801512e+00,  6.46553487e-02, -3.00353616e-01,\n",
      "        -2.30995029e-01, -4.75720882e-01, -9.51742679e-02, -2.92044461e-01,\n",
      "        -3.54145229e-01,  2.51646698e-01,  6.32314205e-01, -8.68146569e-02,\n",
      "         3.47173750e-01,  1.05036342e+00,  1.33203208e-01, -1.81021661e-01,\n",
      "         1.37833804e-01, -1.90640867e-01, -2.11162940e-01,  8.08936000e-01],\n",
      "       dtype=float32)\n",
      " 0 1 3 0]\n"
     ]
    }
   ],
   "source": [
    "with open(\"utterances.npy\", \"rb\") as f:\n",
    "    test = np.load(f, allow_pickle=True)\n",
    "print(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e3828215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2178309"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utt_np_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "105599b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_split = np.array_split(utt_np_arr, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "af2cb54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726103"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utt_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "07eb6ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(726103, 5)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_split[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d23c89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for a in utt_split:\n",
    "    counter += 1\n",
    "    with open(f\"utterances-{counter}.npy\", \"wb\") as f:\n",
    "        np.save(f, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a19dacc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(726103, 5)\n",
      "(726103, 5)\n",
      "(726103, 5)\n"
     ]
    }
   ],
   "source": [
    "for a in utt_split:\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1a1a4c",
   "metadata": {},
   "source": [
    "## Grouping Utterances by Case for Case Level Classification\n",
    "\n",
    "I wanted to try creating documents for each case in the event that we wanted to do case-level classification. \n",
    "\n",
    "Just going to concatenate all text for the cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77964f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_df_cpy = utterances_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ede14",
   "metadata": {},
   "source": [
    "Also going to remove some columns to make this next part simpler..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "279ac9c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meta.case_id</th>\n",
       "      <th>meta.cleaned</th>\n",
       "      <th>meta.win_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number 71, Lonnie Affronti versus United State...</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>number &lt;number&gt; lonnie affronti versus united ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May it please the Court.\\nWe are here by writ ...</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>may please court writ certiorari eighth circui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consecutive sentences.</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>consecutive sentence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consecutive sentences.\\nIn this case, the defe...</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>consecutive sentence case defendant affronti i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was the aggregate prison sentence was 20 or 25...</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>aggregate prison sentence &lt;number&gt; &lt;number&gt; year</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179509</th>\n",
       "      <td>-- has all sorts of meaning that you're not en...</td>\n",
       "      <td>2019_19-67</td>\n",
       "      <td>sort meaning youre endorsing youre saying aidi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179510</th>\n",
       "      <td>No, Your Honor --</td>\n",
       "      <td>2019_19-67</td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179511</th>\n",
       "      <td>-- altogether?</td>\n",
       "      <td>2019_19-67</td>\n",
       "      <td>altogether</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179512</th>\n",
       "      <td>-- we are using the principles of complicity a...</td>\n",
       "      <td>2019_19-67</td>\n",
       "      <td>using principle complicity solicitation statut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179513</th>\n",
       "      <td>Thank you, counsel.\\nThe case is submitted.</td>\n",
       "      <td>2019_19-67</td>\n",
       "      <td>thank counsel case submitted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2178309 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text meta.case_id  \\\n",
       "0        Number 71, Lonnie Affronti versus United State...      1955_71   \n",
       "1        May it please the Court.\\nWe are here by writ ...      1955_71   \n",
       "2                                   Consecutive sentences.      1955_71   \n",
       "3        Consecutive sentences.\\nIn this case, the defe...      1955_71   \n",
       "4        Was the aggregate prison sentence was 20 or 25...      1955_71   \n",
       "...                                                    ...          ...   \n",
       "2179509  -- has all sorts of meaning that you're not en...   2019_19-67   \n",
       "2179510                                  No, Your Honor --   2019_19-67   \n",
       "2179511                                     -- altogether?   2019_19-67   \n",
       "2179512  -- we are using the principles of complicity a...   2019_19-67   \n",
       "2179513        Thank you, counsel.\\nThe case is submitted.   2019_19-67   \n",
       "\n",
       "                                              meta.cleaned meta.win_side  \n",
       "0        number <number> lonnie affronti versus united ...             0  \n",
       "1        may please court writ certiorari eighth circui...             0  \n",
       "2                                     consecutive sentence             0  \n",
       "3        consecutive sentence case defendant affronti i...             0  \n",
       "4         aggregate prison sentence <number> <number> year             0  \n",
       "...                                                    ...           ...  \n",
       "2179509  sort meaning youre endorsing youre saying aidi...             1  \n",
       "2179510                                              honor             1  \n",
       "2179511                                         altogether             1  \n",
       "2179512  using principle complicity solicitation statut...             1  \n",
       "2179513                       thank counsel case submitted             1  \n",
       "\n",
       "[2178309 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_df_cpy.drop(columns=['speaker', 'reply_to', 'conversation_id',\n",
    "                         'meta.start_times', 'meta.stop_times', \n",
    "                         'meta.speaker_type', 'meta.side', \n",
    "                         'meta.timestamp', 'vectors', 'timestamp', \n",
    "                         'meta.votes_side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d38f0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta.case_id</th>\n",
       "      <th>meta.win_side</th>\n",
       "      <th>meta.cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955_10</td>\n",
       "      <td>0</td>\n",
       "      <td>number &lt;number&gt; commonwealth pennsylvania vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1955_102</td>\n",
       "      <td>0</td>\n",
       "      <td>minute remaining simply desire point brief dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955_110</td>\n",
       "      <td>1</td>\n",
       "      <td>court dennis case one cited brief reading beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1955_111</td>\n",
       "      <td>1</td>\n",
       "      <td>number &lt;number&gt; gonzales versus hr landon dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1955_112</td>\n",
       "      <td>1</td>\n",
       "      <td>number &lt;number&gt; amos reece versus state georgi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>2019_19-631</td>\n",
       "      <td>0</td>\n",
       "      <td>well hear argument next case &lt;number&gt; william ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>2019_19-635</td>\n",
       "      <td>0</td>\n",
       "      <td>well hear argument next case &lt;number&gt; donald t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>2019_19-67</td>\n",
       "      <td>1</td>\n",
       "      <td>well hear argument morning case &lt;number&gt; unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6714</th>\n",
       "      <td>2019_19-7</td>\n",
       "      <td>1</td>\n",
       "      <td>well hear argument first morning case &lt;number&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6715</th>\n",
       "      <td>2019_19-715</td>\n",
       "      <td>1</td>\n",
       "      <td>first case argue today case &lt;number&gt; donald tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6716 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     meta.case_id  meta.win_side  \\\n",
       "0         1955_10              0   \n",
       "1        1955_102              0   \n",
       "2        1955_110              1   \n",
       "3        1955_111              1   \n",
       "4        1955_112              1   \n",
       "...           ...            ...   \n",
       "6711  2019_19-631              0   \n",
       "6712  2019_19-635              0   \n",
       "6713   2019_19-67              1   \n",
       "6714    2019_19-7              1   \n",
       "6715  2019_19-715              1   \n",
       "\n",
       "                                           meta.cleaned  \n",
       "0     number <number> commonwealth pennsylvania vers...  \n",
       "1     minute remaining simply desire point brief dec...  \n",
       "2     court dennis case one cited brief reading beca...  \n",
       "3     number <number> gonzales versus hr landon dist...  \n",
       "4     number <number> amos reece versus state georgi...  \n",
       "...                                                 ...  \n",
       "6711  well hear argument next case <number> william ...  \n",
       "6712  well hear argument next case <number> donald t...  \n",
       "6713  well hear argument morning case <number> unite...  \n",
       "6714  well hear argument first morning case <number>...  \n",
       "6715  first case argue today case <number> donald tr...  \n",
       "\n",
       "[6716 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_df_cpy.groupby(['meta.case_id', 'meta.win_side'])['meta.cleaned'].apply(\" \".join).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scotus",
   "language": "python",
   "name": "scotus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
